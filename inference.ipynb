{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "140926f1-774d-4fa2-9bff-6f2af2b4e66b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2, functional\n",
    "from IPython.display import Video\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "\n",
    "from model.titok import TiTok\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from decord import VideoReader, cpu, bridge\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e97141d6-ecb3-4c32-bd44-2abb34906824",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = \"cpu\"\n",
    "torch_dtype = torch.bfloat16\n",
    "\n",
    "config =  OmegaConf.load(\"configs/tiny.yaml\")\n",
    "checkpoint_path = \"out_tiny_w512_exp/epoch=0-step=51000.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c35007-978b-4ce4-9140-dac536a6971d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = TiTok(config)\n",
    "\n",
    "if config.training.torch_compile:\n",
    "    tokenizer = torch.compile(tokenizer.to(device))\n",
    "\n",
    "orig_sd = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=False)['state_dict']\n",
    "global_step = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=False)['global_step']\n",
    "\n",
    "model_sd = {}\n",
    "for k, v in orig_sd.items():\n",
    "    if 'loss_module' not in k:\n",
    "        model_sd[k[6:]] = v\n",
    "    \n",
    "tokenizer.load_state_dict(model_sd)\n",
    "tokenizer.eval().to(device, torch_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b2ce9a-dc1d-4c04-8086-b9c8fb83f98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bridge.set_bridge('torch')\n",
    "trg_res = config.dataset.resolution\n",
    "num_frames = config.dataset.num_frames\n",
    "dataset_fps = config.dataset.frames_per_second\n",
    "\n",
    "transforms = v2.Compose([\n",
    "            v2.Resize(size=trg_res, interpolation=functional.InterpolationMode.BICUBIC, antialias=True),\n",
    "            v2.CenterCrop(size=trg_res),\n",
    "            v2.UniformTemporalSubsample(num_frames),\n",
    "            v2.ToImage(),\n",
    "            v2.ToDtype(torch_dtype, scale=True),\n",
    "            v2.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]), # [-1, 1]      \n",
    "])\n",
    "\n",
    "# Tokenize a video\n",
    "def tokenize_and_reconstruct(video_path, write_path):\n",
    "    with torch.no_grad():\n",
    "        vr = VideoReader(video_path, ctx=cpu(0))\n",
    "        fps = vr.get_avg_fps()\n",
    "        video = vr.get_batch(list(range(len(vr)))) # get all frames\n",
    "        video = video[:int(fps/dataset_fps*num_frames)]\n",
    "    \n",
    "        orig = transforms(video.permute(0, 3, 1, 2)).permute(1, 0, 2, 3).to(device, torch_dtype)\n",
    "        z_quant, result_dict = tokenizer.encode(orig.unsqueeze(0))\n",
    "\n",
    "        tokens_list = result_dict['codes'].cpu().tolist()[0]\n",
    "        print(f\"VIDEO TOKENS ({len(tokens_list)}):\\n{tokens_list}\")\n",
    "        z_quant = tokenizer.quantize.indices_to_codes(result_dict['codes'])\n",
    "        \n",
    "        recon = tokenizer.decode(z_quant.to(torch_dtype)).clamp(-1, 1).squeeze(0)\n",
    "\n",
    "        merged_video = torch.cat((orig, recon), dim=-1).permute(1, 2, 3, 0).cpu().float().numpy() # cth(W) concat -> thwc\n",
    "        merged_video = ((merged_video + 1) / 2 * 255).astype(np.uint8)\n",
    "        imageio.mimwrite(write_path, merged_video, fps=fps, quality=8)\n",
    "        # Video(write_path, width=trg_res*2, height=trg_res, embed=True) # display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3822d54-1ca8-413f-b591-0ad70d57b00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_and_reconstruct(f\"assets/orig.mp4\", f\"assets/recon_{config.logging.run_name}_{global_step}.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acfa2806-6734-45ae-8dd6-77ee8e5f9223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval dataset for single multi-chunk-duration video\n",
    "class EvalReconstructionDataset(torch.utils.data.Dataset): # assumes videos are > target in frames, res, etc.\n",
    "    def __init__(self, video_path, trg_fps=8, trg_frames=8, trg_res=128):\n",
    "        self.trg_frames = trg_frames\n",
    "        self.trg_fps = trg_fps\n",
    "        self.video_path = video_path\n",
    "        self.transform = v2.Compose([\n",
    "            v2.Resize(size=trg_res, interpolation=functional.InterpolationMode.BICUBIC, antialias=True),\n",
    "            v2.CenterCrop(size=trg_res)\n",
    "        ])\n",
    "        bridge.set_bridge('torch')\n",
    "        self.vr = VideoReader(video_path, ctx=cpu(0), num_threads=0)\n",
    "\n",
    "        self.orig_fps_chunk_length = int(trg_frames * (self.vr.get_avg_fps() / trg_fps))\n",
    "        self.num_chunks = len(self.vr) // self.orig_fps_chunk_length\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_chunks\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_idx = idx * self.orig_fps_chunk_length\n",
    "        end_idx = start_idx + self.orig_fps_chunk_length\n",
    "    \n",
    "        chunk_indices = np.linspace(start_idx, end_idx - 1, self.trg_frames, dtype=int).tolist()\n",
    "        chunk = torch.Tensor(self.vr.get_batch(chunk_indices))\n",
    "    \n",
    "        chunk = chunk.permute(0, 3, 1, 2)\n",
    "        chunk = self.transform(chunk)\n",
    "        chunk = chunk.permute(1, 0, 2, 3)\n",
    "    \n",
    "        chunk = chunk.to(torch_dtype) / 255\n",
    "        chunk = (chunk * 2) - 1 # [-1, 1]\n",
    "\n",
    "        return chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf4c3b20-94bd-464d-962f-3c209ff45e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "trg_res = config.dataset.resolution\n",
    "num_frames = config.dataset.num_frames\n",
    "dataset_fps = config.dataset.frames_per_second\n",
    "\n",
    "# Tokenize a video (batched)\n",
    "def tokenize_and_reconstruct(video_path, write_path, batch_size=1, workers=0): # would desync with many workers?\n",
    "    with torch.no_grad(), imageio.v3.imopen(write_path, \"w\", plugin=\"pyav\") as video_writer:\n",
    "        dataset = EvalReconstructionDataset(video_path, dataset_fps, num_frames, trg_res)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=0)\n",
    "        video_writer.init_video_stream(\"libx264\", fps=dataset_fps)\n",
    "        video_writer._video_stream.options = {'crf': '0'} # lossless\n",
    "\n",
    "        for batch in dataloader:\n",
    "            recon = tokenizer(batch)[0].clamp(-1, 1)\n",
    "            \n",
    "            orig = rearrange(batch, \"b c t h w -> (b t) h w c\")\n",
    "            recon = rearrange(recon, \"b c t h w -> (b t) h w c\")\n",
    "\n",
    "            merged_video = torch.cat((orig, recon), dim=2).cpu().float().numpy() # th(W)c concat\n",
    "            merged_video = ((merged_video + 1) / 2 * 255).astype(np.uint8)\n",
    "            for frame in merged_video:\n",
    "                video_writer.write_frame(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100a1001-79a7-4ae5-8cc8-edcf291acaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_and_reconstruct(f\"assets/orig_long.mp4\", f\"assets/recon_long_{config.logging.run_name}_{global_step}.mp4\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ff9c95-fb92-41ec-a063-16c1fd72cf47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
