{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140926f1-774d-4fa2-9bff-6f2af2b4e66b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2, functional\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "from omegaconf import OmegaConf\n",
    "from decord import VideoReader, cpu, bridge\n",
    "import imageio\n",
    "\n",
    "from model.titok import TiTok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e97141d6-ecb3-4c32-bd44-2abb34906824",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = \"cuda\"\n",
    "torch_dtype = torch.bfloat16\n",
    "\n",
    "config = OmegaConf.load(\"configs/large.yaml\")\n",
    "checkpoint_path = \"model.ckpt\" # hf download NilanE/TiTok-Video-VariableComp-V1 model.ckpt --local-dir .\n",
    "use_ema = True # False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3c35007-978b-4ce4-9140-dac536a6971d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TiTok(\n",
       "  (encoder): TiTokEncoder(\n",
       "    (rope): RoPE(\n",
       "      (pos_emb): Lumina2RotaryPosEmbed()\n",
       "    )\n",
       "    (proj_in): Linear(in_features=768, out_features=1024, bias=True)\n",
       "    (model_layers): ResidualAttentionBlock(\n",
       "      (attn_layer): Sequential(\n",
       "        (0): Attn(\n",
       "          (pre_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_qkv): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (1): Attn(\n",
       "          (pre_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_qkv): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (2): Attn(\n",
       "          (pre_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_qkv): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (3): Attn(\n",
       "          (pre_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_qkv): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (4): Attn(\n",
       "          (pre_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_qkv): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (5): Attn(\n",
       "          (pre_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_qkv): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (6): Attn(\n",
       "          (pre_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_qkv): Linear(in_features=1024, out_features=1536, bias=False)\n",
       "          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (ffd_layer): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=1024, out_features=2752, bias=False)\n",
       "          (2): GEGLU()\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "          (4): Linear(in_features=1376, out_features=1024, bias=False)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=1024, out_features=2752, bias=False)\n",
       "          (2): GEGLU()\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "          (4): Linear(in_features=1376, out_features=1024, bias=False)\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=1024, out_features=2752, bias=False)\n",
       "          (2): GEGLU()\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "          (4): Linear(in_features=1376, out_features=1024, bias=False)\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=1024, out_features=2752, bias=False)\n",
       "          (2): GEGLU()\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "          (4): Linear(in_features=1376, out_features=1024, bias=False)\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=1024, out_features=2752, bias=False)\n",
       "          (2): GEGLU()\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "          (4): Linear(in_features=1376, out_features=1024, bias=False)\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=1024, out_features=2752, bias=False)\n",
       "          (2): GEGLU()\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "          (4): Linear(in_features=1376, out_features=1024, bias=False)\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=1024, out_features=2752, bias=False)\n",
       "          (2): GEGLU()\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "          (4): Linear(in_features=1376, out_features=1024, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (proj_out): Linear(in_features=1024, out_features=5, bias=True)\n",
       "  )\n",
       "  (quantize): FSQ()\n",
       "  (decoder): TiTokDecoder(\n",
       "    (rope): RoPE(\n",
       "      (pos_emb): Lumina2RotaryPosEmbed()\n",
       "    )\n",
       "    (proj_in): Linear(in_features=5, out_features=2048, bias=True)\n",
       "    (ln_pre): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    (model_layers): ResidualAttentionBlock(\n",
       "      (attn_layer): Sequential(\n",
       "        (0): Attn(\n",
       "          (pre_ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_qkv): Linear(in_features=2048, out_features=3072, bias=False)\n",
       "          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (1): Attn(\n",
       "          (pre_ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_qkv): Linear(in_features=2048, out_features=3072, bias=False)\n",
       "          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (2): Attn(\n",
       "          (pre_ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_qkv): Linear(in_features=2048, out_features=3072, bias=False)\n",
       "          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (3): Attn(\n",
       "          (pre_ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_qkv): Linear(in_features=2048, out_features=3072, bias=False)\n",
       "          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (4): Attn(\n",
       "          (pre_ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_qkv): Linear(in_features=2048, out_features=3072, bias=False)\n",
       "          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (5): Attn(\n",
       "          (pre_ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_qkv): Linear(in_features=2048, out_features=3072, bias=False)\n",
       "          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (6): Attn(\n",
       "          (pre_ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_qkv): Linear(in_features=2048, out_features=3072, bias=False)\n",
       "          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (7): Attn(\n",
       "          (pre_ln): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_qkv): Linear(in_features=2048, out_features=3072, bias=False)\n",
       "          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (out_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (ffd_layer): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=2048, out_features=5504, bias=False)\n",
       "          (2): GEGLU()\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "          (4): Linear(in_features=2752, out_features=2048, bias=False)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=2048, out_features=5504, bias=False)\n",
       "          (2): GEGLU()\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "          (4): Linear(in_features=2752, out_features=2048, bias=False)\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=2048, out_features=5504, bias=False)\n",
       "          (2): GEGLU()\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "          (4): Linear(in_features=2752, out_features=2048, bias=False)\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=2048, out_features=5504, bias=False)\n",
       "          (2): GEGLU()\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "          (4): Linear(in_features=2752, out_features=2048, bias=False)\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=2048, out_features=5504, bias=False)\n",
       "          (2): GEGLU()\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "          (4): Linear(in_features=2752, out_features=2048, bias=False)\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=2048, out_features=5504, bias=False)\n",
       "          (2): GEGLU()\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "          (4): Linear(in_features=2752, out_features=2048, bias=False)\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=2048, out_features=5504, bias=False)\n",
       "          (2): GEGLU()\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "          (4): Linear(in_features=2752, out_features=2048, bias=False)\n",
       "        )\n",
       "        (7): Sequential(\n",
       "          (0): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=2048, out_features=5504, bias=False)\n",
       "          (2): GEGLU()\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "          (4): Linear(in_features=2752, out_features=2048, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (proj_out): Linear(in_features=2048, out_features=768, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = TiTok(config)\n",
    "\n",
    "if config.training.main.torch_compile:\n",
    "    tokenizer = torch.compile(tokenizer.to(device))\n",
    "\n",
    "orig_sd = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=False)['state_dict']\n",
    "global_step = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=False)['global_step']\n",
    "\n",
    "model_sd = {}\n",
    "model_key = 'ema_model' if (use_ema and any([k.startswith('ema_model') for k in orig_sd.keys()])) else 'model'\n",
    "\n",
    "for k, v in orig_sd.items():\n",
    "    if k.startswith(model_key):\n",
    "        model_sd[k[(len(model_key)+1):]] = v\n",
    "    \n",
    "tokenizer.load_state_dict(model_sd)\n",
    "tokenizer.eval().to(device, torch_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acfa2806-6734-45ae-8dd6-77ee8e5f9223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval dataset for single multi-chunk-duration video\n",
    "class EvalReconstructionDataset(torch.utils.data.Dataset): # assumes videos are > target in frames, res, etc.\n",
    "    def __init__(self, video_path, trg_fps=8, out_grid=(16, 128, 128)):\n",
    "        self.out_grid = out_grid\n",
    "        self.video_path = video_path\n",
    "        self.transform = v2.Compose([\n",
    "            v2.Resize(size=max(out_grid[1:]), interpolation=functional.InterpolationMode.BICUBIC, antialias=True),\n",
    "            v2.CenterCrop(size=out_grid[1:])\n",
    "        ])\n",
    "        bridge.set_bridge('torch')\n",
    "        self.vr = VideoReader(video_path, ctx=cpu(0), num_threads=0)\n",
    "\n",
    "        self.orig_fps_chunk_length = int(out_grid[0] * (self.vr.get_avg_fps() / trg_fps))\n",
    "        self.num_chunks = len(self.vr) // self.orig_fps_chunk_length\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_chunks\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_idx = idx * self.orig_fps_chunk_length\n",
    "        end_idx = start_idx + self.orig_fps_chunk_length\n",
    "    \n",
    "        chunk_indices = np.linspace(start_idx, end_idx - 1, self.out_grid[0], dtype=int).tolist()\n",
    "        chunk = torch.Tensor(self.vr.get_batch(chunk_indices))\n",
    "    \n",
    "        chunk = chunk.permute(0, 3, 1, 2)\n",
    "        chunk = self.transform(chunk)\n",
    "        chunk = chunk.permute(1, 0, 2, 3)\n",
    "    \n",
    "        chunk = chunk.to(device, torch_dtype) / 255\n",
    "        chunk = (chunk * 2) - 1 # [-1, 1]\n",
    "\n",
    "        return chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4c3b20-94bd-464d-962f-3c209ff45e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize a video (batched)\n",
    "def tokenize_and_reconstruct(video_path, write_path, grid, num_tokens, ds_fps, batch_size=1):\n",
    "    with torch.no_grad(), imageio.v3.imopen(write_path, \"w\", plugin=\"pyav\") as video_writer:\n",
    "        dataset = EvalReconstructionDataset(video_path, ds_fps, grid)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=0)\n",
    "\n",
    "        video_writer.init_video_stream(\"h264\", fps=ds_fps)\n",
    "        video_writer._video_stream.options = {'crf': '0'} # lossless\n",
    "        video_writer._video_stream.codec_context.time_base = video_writer._video_stream.time_base\n",
    "\n",
    "        for batch in dataloader:\n",
    "            recon = torch.stack(tokenizer(batch.unbind(0), [num_tokens]*batch_size)[0], dim=0).clamp(-1, 1)\n",
    "\n",
    "            # ### same effect as the above line, but more verbose\n",
    "            # compressed_tokens = tokenizer.encode(batch.unbind(0), [num_tokens]*batch_size)[1]['indices']\n",
    "            # compressed_tokens = torch.cat(compressed_tokens, dim=0)\n",
    "            # print(f\"VIDEO TOKENS ({compressed_tokens.shape[0]}):\\n{compressed_tokens.tolist()}\")\n",
    "\n",
    "            # recon = tokenizer.decode_indices(compressed_tokens, [num_tokens]*batch_size, [grid]*batch_size)\n",
    "            # recon = torch.stack(recon, dim=0).clamp(-1, 1)\n",
    "            # ###\n",
    "            \n",
    "            orig = rearrange(batch, \"b c t h w -> (b t) h w c\")\n",
    "            recon = rearrange(recon, \"b c t h w -> (b t) h w c\")\n",
    "\n",
    "            merged_video = torch.cat((orig, recon), dim=2).detach().cpu().float().numpy() # th(W)c concat\n",
    "            merged_video = ((merged_video + 1) / 2 * 255).astype(np.uint8)\n",
    "            \n",
    "            for frame in merged_video:\n",
    "                video_writer.write_frame(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100a1001-79a7-4ae5-8cc8-edcf291acaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = (20, 192, 192) # frames, H-res, W-res per encode\n",
    "num_tokens = 224 # 128, 224, 1024, etc.\n",
    "fps = 8 # sampling FPS\n",
    "\n",
    "in_video = \"big_buck_bunny_480p_h264.mov\" # https://download.blender.org/peach/bigbuckbunny_movies/big_buck_bunny_480p_h264.mov\n",
    "out_video = '.'.join(in_video.split('.')[:-1]) + f\"_TL{num_tokens}{'_EMA' if use_ema else ''}.mp4\"\n",
    "\n",
    "tokenize_and_reconstruct(in_video, out_video, grid, num_tokens, fps, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bb8bda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
