{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38b4fdd0-df97-4374-bc83-f243115ce7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import glob\n",
    "import ffmpeg\n",
    "from omegaconf import OmegaConf\n",
    "from einops import rearrange\n",
    "import gdown\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model.titok import TiTok\n",
    "from base_tokenizers import load_vae\n",
    "\n",
    "from torchmetrics.image import PeakSignalNoiseRatio, LearnedPerceptualImagePatchSimilarity, StructuralSimilarityIndexMeasure\n",
    "from torchmetrics import MetricCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecb66e54-86ac-40bd-a8f0-1397ae3ed2bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1b0oxiZ3udGJ9Re-CeUTYg-EUorNX3Y7J videoSRC01_1280x720_30.yuv\n",
      "Processing file 1DHBUXCHroqC7MXR1bL3P8mfEGlUDjRl0 videoSRC02_1280x720_30.yuv\n",
      "Processing file 1EVj4S4MheQ8L3voaQ6LKMf0cySTh7gLK videoSRC03_1280x720_30.yuv\n",
      "Processing file 1K4w5pUbSFNr46FQnssmeTpgiRTETqRiN videoSRC04_1280x720_30.yuv\n",
      "Processing file 1j8Oh0Agdfo-BFtN2i2hgytM8ArjKHx5q videoSRC05_1280x720_25.yuv\n",
      "Processing file 1EeSFFcs16QHkz4JZOAtG42K0qt-6XDaq videoSRC06_1280x720_25.yuv\n",
      "Processing file 1aNdQmPGuEpxUp8JDXZfzy18PmKUrSfyu videoSRC07_1280x720_25.yuv\n",
      "Processing file 1l-AZ1CS6bS84qixmD7L2Go_g48b736HN videoSRC08_1280x720_25.yuv\n",
      "Processing file 1BdVeZ7GIWcUfNSgCgWxZOom7LjO_Z6FM videoSRC09_1280x720_25.yuv\n",
      "Processing file 1U3q2ttP1SSg4I-1ZjqrhVe0tbvRud2G_ videoSRC10_1280x720_30.yuv\n",
      "Processing file 1_KZp7H5LdLMVTQEDSg7x2wzZc0PrViLX videoSRC11_1280x720_30.yuv\n",
      "Processing file 1gMX-z0x9jxaplh7-sv8LL7tihmxUebol videoSRC12_1280x720_30.yuv\n",
      "Processing file 1WL2kCcvpqy-CZXtlp_cE9kK-2OOJR_7j videoSRC13_1280x720_30.yuv\n",
      "Processing file 1pdnPCXP9hcLs1i-TL6J1HJVW61lQ-vvB videoSRC14_1280x720_30.yuv\n",
      "Processing file 1WnVhKdW36lbLNmrnplM8srCH1E089hlH videoSRC15_1280x720_30.yuv\n",
      "Processing file 1PDIl_c9IVBuVLMN9lCqlyBe1iwbZWdT5 videoSRC16_1280x720_30.yuv\n",
      "Processing file 1H8lGESkk8lRqIcetgD-RNSQ9xaqUTQJ4 videoSRC17_1280x720_24.yuv\n",
      "Processing file 1PF7V38xI0VWh0lLzKrX369i_uCaa0hKF videoSRC18_1280x720_25.yuv\n",
      "Processing file 1JPmfhdQHxMV5DKD9fgwzaUVd2VARbdgk videoSRC19_1280x720_30.yuv\n",
      "Processing file 14OEfS2I7JuTI9fwZOYnvQseWzdgPd6rq videoSRC20_1280x720_25.yuv\n",
      "Processing file 1joEIZkx_y130x6SmDeZg7a4Dsi5Fvohj videoSRC21_1280x720_24.yuv\n",
      "Processing file 1Y6ylPd464HxPjkmybo-CgFGqDvRq77MH videoSRC22_1280x720_24.yuv\n",
      "Processing file 16d2bevTSez-afi5GKH-XsgZT67J1qtvh videoSRC23_1280x720_24.yuv\n",
      "Processing file 1ZLVN_JbhoVcYPVDqH68gBz58eJHnAN0Y videoSRC24_1280x720_24.yuv\n",
      "Processing file 1goKtq_qKFTBZL53bSonvnMbCj_vHSpMb videoSRC25_1280x720_24.yuv\n",
      "Processing file 1emSkk8J5HkPjJfFUN2p-tht3bOZ56rSq videoSRC26_1280x720_30.yuv\n",
      "Processing file 1LQ4l0zs7nhktgWMAuw4XIm_RMR4L9V0V videoSRC27_1280x720_30.yuv\n",
      "Processing file 1jY3UIm7Mx1MON3zlA7mf3r5pLKH6LWry videoSRC28_1280x720_30.yuv\n",
      "Processing file 1EUF0WY5cEYcQ4WmfiCiz1Hbz2ocJJH3b videoSRC29_1280x720_24.yuv\n",
      "Processing file 1QJEUx1u0bR1rETUBi9TzZ8IlVRFjV_FX videoSRC30_1280x720_30.yuv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents completed\n",
      "Building directory structure\n",
      "Building directory structure completed\n",
      "Skipping already downloaded file val_dataset/videoSRC01_1280x720_30.yuv\n",
      "Skipping already downloaded file val_dataset/videoSRC02_1280x720_30.yuv\n",
      "Skipping already downloaded file val_dataset/videoSRC03_1280x720_30.yuv\n",
      "Skipping already downloaded file val_dataset/videoSRC04_1280x720_30.yuv\n",
      "Skipping already downloaded file val_dataset/videoSRC05_1280x720_25.yuv\n",
      "Skipping already downloaded file val_dataset/videoSRC06_1280x720_25.yuv\n",
      "Skipping already downloaded file val_dataset/videoSRC07_1280x720_25.yuv\n",
      "Skipping already downloaded file val_dataset/videoSRC08_1280x720_25.yuv\n",
      "Skipping already downloaded file val_dataset/videoSRC09_1280x720_25.yuv\n",
      "Skipping already downloaded file val_dataset/videoSRC10_1280x720_30.yuv\n",
      "Skipping already downloaded file val_dataset/videoSRC11_1280x720_30.yuv\n",
      "Skipping already downloaded file val_dataset/videoSRC12_1280x720_30.yuv\n",
      "Skipping already downloaded file val_dataset/videoSRC13_1280x720_30.yuv\n",
      "Skipping already downloaded file val_dataset/videoSRC14_1280x720_30.yuv\n",
      "Skipping already downloaded file val_dataset/videoSRC15_1280x720_30.yuv\n",
      "Skipping already downloaded file val_dataset/videoSRC16_1280x720_30.yuv\n",
      "Skipping already downloaded file val_dataset/videoSRC17_1280x720_24.yuv\n",
      "Skipping already downloaded file val_dataset/videoSRC18_1280x720_25.yuv\n",
      "Skipping already downloaded file val_dataset/videoSRC19_1280x720_30.yuv\n",
      "Skipping already downloaded file val_dataset/videoSRC20_1280x720_25.yuv\n",
      "Skipping already downloaded file val_dataset/videoSRC21_1280x720_24.yuv\n",
      "Skipping already downloaded file val_dataset/videoSRC22_1280x720_24.yuv\n",
      "Skipping already downloaded file val_dataset/videoSRC23_1280x720_24.yuv\n",
      "Skipping already downloaded file val_dataset/videoSRC24_1280x720_24.yuv\n",
      "Skipping already downloaded file val_dataset/videoSRC25_1280x720_24.yuv\n",
      "Skipping already downloaded file val_dataset/videoSRC26_1280x720_30.yuv\n",
      "Skipping already downloaded file val_dataset/videoSRC27_1280x720_30.yuv\n",
      "Skipping already downloaded file val_dataset/videoSRC28_1280x720_30.yuv\n",
      "Skipping already downloaded file val_dataset/videoSRC29_1280x720_24.yuv\n",
      "Skipping already downloaded file val_dataset/videoSRC30_1280x720_30.yuv\n",
      "Download completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['val_dataset/videoSRC01_1280x720_30.yuv',\n",
       " 'val_dataset/videoSRC02_1280x720_30.yuv',\n",
       " 'val_dataset/videoSRC03_1280x720_30.yuv',\n",
       " 'val_dataset/videoSRC04_1280x720_30.yuv',\n",
       " 'val_dataset/videoSRC05_1280x720_25.yuv',\n",
       " 'val_dataset/videoSRC06_1280x720_25.yuv',\n",
       " 'val_dataset/videoSRC07_1280x720_25.yuv',\n",
       " 'val_dataset/videoSRC08_1280x720_25.yuv',\n",
       " 'val_dataset/videoSRC09_1280x720_25.yuv',\n",
       " 'val_dataset/videoSRC10_1280x720_30.yuv',\n",
       " 'val_dataset/videoSRC11_1280x720_30.yuv',\n",
       " 'val_dataset/videoSRC12_1280x720_30.yuv',\n",
       " 'val_dataset/videoSRC13_1280x720_30.yuv',\n",
       " 'val_dataset/videoSRC14_1280x720_30.yuv',\n",
       " 'val_dataset/videoSRC15_1280x720_30.yuv',\n",
       " 'val_dataset/videoSRC16_1280x720_30.yuv',\n",
       " 'val_dataset/videoSRC17_1280x720_24.yuv',\n",
       " 'val_dataset/videoSRC18_1280x720_25.yuv',\n",
       " 'val_dataset/videoSRC19_1280x720_30.yuv',\n",
       " 'val_dataset/videoSRC20_1280x720_25.yuv',\n",
       " 'val_dataset/videoSRC21_1280x720_24.yuv',\n",
       " 'val_dataset/videoSRC22_1280x720_24.yuv',\n",
       " 'val_dataset/videoSRC23_1280x720_24.yuv',\n",
       " 'val_dataset/videoSRC24_1280x720_24.yuv',\n",
       " 'val_dataset/videoSRC25_1280x720_24.yuv',\n",
       " 'val_dataset/videoSRC26_1280x720_30.yuv',\n",
       " 'val_dataset/videoSRC27_1280x720_30.yuv',\n",
       " 'val_dataset/videoSRC28_1280x720_30.yuv',\n",
       " 'val_dataset/videoSRC29_1280x720_24.yuv',\n",
       " 'val_dataset/videoSRC30_1280x720_30.yuv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download MCL_JCV 720p source dataset\n",
    "gdrive_ds = 'https://drive.google.com/drive/folders/12A8gk07j3OppdcY5JbxSg-ozw_BXzcIQ'\n",
    "val_ds_path = 'val_dataset'\n",
    "os.makedirs(val_ds_path, exist_ok=True)\n",
    "gdown.download_folder(gdrive_ds, output=val_ds_path, resume=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19d439b5-78eb-4583-a5b1-0dbadd0d7dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = \"cuda\"\n",
    "torch_dtype = torch.bfloat16\n",
    "\n",
    "config =  OmegaConf.load(\"stage_2/config.yaml\")\n",
    "checkpoint_path = \"stage_2/model.ckpt\"\n",
    "vae_path = \"wfvae-16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4915e75-d170-4440-a93e-36f2b8d1dab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TiTok(config)\n",
    "\n",
    "if config.training.torch_compile:\n",
    "    tokenizer = torch.compile(tokenizer.to(device))\n",
    "\n",
    "orig_sd = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=False)['state_dict']\n",
    "model_sd = {}\n",
    "for k, v in orig_sd.items():\n",
    "    if not 'disc' in k:\n",
    "        model_sd[k[6:]] = v\n",
    "    \n",
    "tokenizer.load_state_dict(model_sd)\n",
    "tokenizer.eval().to(device, torch_dtype)\n",
    "vae = load_vae(vae_name=config.model.vae.type, model_path=vae_path, embed_dim=config.model.vae.latent_channels)\n",
    "vae.eval().to(device, torch_dtype)\n",
    "\n",
    "vae_metrics = MetricCollection(\n",
    "    {\n",
    "        \"psnr\": PeakSignalNoiseRatio(),\n",
    "        \"ssim\": StructuralSimilarityIndexMeasure(),\n",
    "        \"lpips\": LearnedPerceptualImagePatchSimilarity(net_type='vgg').eval(),\n",
    "    }\n",
    ").to(device, torch_dtype)\n",
    "\n",
    "titok_metrics = vae_metrics.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ce06fda-c776-441b-b6b1-a3f14b505da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/30 [00:00<?, ?it/s]/tmp/ipykernel_39338/519543578.py:22: UserWarning: The given buffer is not writable, and PyTorch does not support non-writable tensors. This means you can write to the underlying (supposedly non-writable) buffer using the tensor. You may want to copy the buffer to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:1560.)\n",
      "  video = torch.frombuffer(out, dtype=torch.uint8).reshape([-1, trg_res, trg_res, 3])\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 30/30 [01:47<00:00,  3.58s/it]\n"
     ]
    }
   ],
   "source": [
    "trg_res = config.dataset.resolution\n",
    "trg_fps = config.dataset.frames_per_second\n",
    "trg_frames = config.dataset.num_frames\n",
    "\n",
    "src_files = glob.glob(os.path.join(val_ds_path, '*.yuv'))\n",
    "num_eval = 0\n",
    "\n",
    "for src_file in tqdm(src_files):\n",
    "    src_fps = src_file.split('_')[-1].replace('.yuv', '')\n",
    "    width, height = [int(i) for i in src_file.split('_')[-2].split('x')]\n",
    "    \n",
    "    x_offset = (width - height) // 2\n",
    "    out, _ = (\n",
    "        ffmpeg.input(src_file, format='rawvideo', pix_fmt='yuv420p', s='{}x{}'.format(width, height), framerate=src_fps)\n",
    "        .crop(x=x_offset, y=0, width='ih', height='ih') # crop to square\n",
    "        .filter('scale', width=trg_res, height=trg_res) # resize\n",
    "        .filter('fps', trg_fps)\n",
    "        .output('pipe:', format='rawvideo', pix_fmt='rgb24', v='error')\n",
    "        .run(capture_stdout=True)\n",
    "    )\n",
    "\n",
    "    video = torch.frombuffer(out, dtype=torch.uint8).reshape([-1, trg_res, trg_res, 3])\n",
    "\n",
    "    if video.shape[0] >= trg_frames:\n",
    "        num_chunks = video.shape[0] // trg_frames\n",
    "        chunked_video = video[:num_chunks*trg_frames].reshape(-1, trg_frames, trg_res, trg_res, 3)\n",
    "        chunked_video = (chunked_video.permute(0, 4, 1, 2, 3).to('cuda:0', torch.bfloat16) / 255) # BTHWC -> BCTHW, 0-255\n",
    "        chunked_video = (chunked_video * 2) - 1.0 # -1, 1\n",
    "\n",
    "        for chunk in chunked_video: # not batching? Only ~30 vids, not worth it?\n",
    "            with torch.no_grad():\n",
    "                vae_encoded = vae.encode(chunk.unsqueeze(0))\n",
    "                titok_encoded, _ = tokenizer(vae_encoded)\n",
    "                titok_decoded = vae.decode(titok_encoded)\n",
    "                vae_decoded = vae.decode(vae_encoded)\n",
    "\n",
    "                recon_titok = rearrange(titok_decoded.squeeze(0), \"c t h w -> t c h w\")\n",
    "                recon_vae = rearrange(vae_decoded.squeeze(0), \"c t h w -> t c h w\")\n",
    "                orig = rearrange(chunk, \"c t h w -> t c h w\")\n",
    "\n",
    "                titok_metrics.update(recon_titok, orig)\n",
    "                vae_metrics.update(recon_vae, orig) # averages automatically\n",
    "    \n",
    "                num_eval += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee979cb3-a196-4ac2-9183-bb2b5c8add72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num eval: 60\n",
      "VAE-only scores:    LPIPS 0.22 | PSNR 24.02 | SSIM 0.81\n",
      "TiTok-Video scores: LPIPS 0.67 | PSNR 14.93 | SSIM 0.36\n"
     ]
    }
   ],
   "source": [
    "vae_scores = vae_metrics.compute()\n",
    "titok_scores = titok_metrics.compute()\n",
    "\n",
    "print(f\"Num eval: {num_eval}\")\n",
    "print(\"VAE-only scores:    \" + ' | '.join([f\"{k.upper()} {v:.2f}\" for k, v in vae_scores.items()]))\n",
    "print(\"TiTok-Video scores: \" + ' | '.join([f\"{k.upper()} {v:.2f}\" for k, v in titok_scores.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15cfe53-7ad6-4a21-b16f-3179326966b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
