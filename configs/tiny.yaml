experiment:
    project: "titok_video_tiny"
    name: "FSQ-TP4_SP8-TS12_TL16-192x16"
    output_dir: "out_tiny"

    max_train_steps: 50000
    max_train_examples: 480000

    save_every: 2000
    eval_every: 500
    generate_every: 500
    log_every: 50
    log_grad_norm_every: 500

    resume: False
    init_weight: ""

model:
    pretrained_vae:
        type: cogvideox # wfvae, cogvideox
        path: base_tokenizer/pretrained_model # point to a folder containing the vae's files from HF.
        latent_channels: 16
        temporal_compression: 4
        spatial_compression: 8
        vae_dtype: "bf16" # wfvae-16ch has minor quality hit at bf16

    titok:
        vit_enc_temporal_patch_size: 4
        vit_enc_spatial_patch_size: 8

        num_latent_tokens: 16

        # mode setting
        quant_mode: "fsq" # vae, fsq, bsq

        # FSQ
        fsq_levels: [8, 8, 5, 5, 5] # CB size: 8000

        # # VAE:
        # token_size: 12
        # kl_weight: 1e-5

        # # BSQ - refer to https://github.com/zhaoyue-zephyrus/bsq-vit:
        # token_size: 12 # CB size: 4096
        # soft_entropy: True
        # l2_norm: True
        # post_q_l2_norm: True

        # commit_loss_weight: 0.

        # persample_entropy_weight: 1.0
        # cb_entropy_weight: 1.0
        # ent_loss_weight: 0.1
        # embed_group_size: 6
        # persample_entropy_compute: analytical
        # cb_entropy_compute: group

        # codebook_rampup_steps: 2000 # 0 to disable ramp
        # codebook_rampup_multiplier: 3.0

        # vit arch
        vit_enc_model_size: "tiny"
        vit_dec_model_size: "tiny"

        attn_and_mlp_residual: False # has slightly better performance when enabled, but diverges from the literature. Not sure if it's stable for long training runs.


video_dataset:
    params:
        train_dataset: "train_dataset/*.pth" # the dataset should be a directory of files containing saved float32 tensors, each one being a VAE-encoded clip of the target resolution and frame count.
        eval_dataset: "eval_dataset/*.pth"
        num_frames: 16
        resolution: 192
        frames_per_second: 8
        dataset_workers: 4


optimizer:
    name: adamw
    params:
        learning_rate: 1e-4
        beta1: 0.9
        beta2: 0.99
        weight_decay: 1e-4
        epsilon: 1e-8

lr_scheduler:
    scheduler: "cosine"
    params:
        learning_rate: ${optimizer.params.learning_rate}
        warmup_steps: 200
        end_lr: 1e-5

training:
    torch_compile: False
    torch_compile_mode: "reduce-overhead"
    torch_compile_backend: "inductor"
    per_gpu_batch_size: 512
    mixed_precision: "bf16"
    enable_tf32: True
    enable_wandb: True
    seed: 42
    max_grad_norm: 1.0

    # for metrics and recon
    recon_batch_size: 1
    num_generated_videos: 4
    metric_eval_num: 32
    codebook_eval_batch_size: 64