model:
    vae_model:
        path: base_tokenizers/pretrained_model
        latent_channels: 16
        temporal_compression: 4
        spatial_compression: 8

    vq_model:
        vit_enc_temporal_patch_size: 4
        vit_enc_spatial_patch_size: 8

        num_latent_tokens: 64

        fsq_levels: [8, 8, 5, 5, 5]

        # vit arch
        vit_enc_model_size: "small"
        vit_dec_model_size: "small"

video_dataset:
    params:
        num_frames: 16 # -3 in the recon due to pretrained causal VAE
        resolution: 192

training:
    torch_compile: False
    torch_compile_mode: "reduce-overhead"
    torch_compile_backend: "inductor"
    enable_tf32: True
    seed: 42